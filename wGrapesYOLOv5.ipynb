{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6MPjfT5NrKQ"
      },
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "  <a href=\"https://ultralytics.com/yolov5\" target=\"_blank\">\n",
        "    <img width=\"1024\", src=\"https://raw.githubusercontent.com/ultralytics/assets/main/yolov5/v70/splash.png\"></a>\n",
        "\n",
        "\n",
        "<br>\n",
        "  <a href=\"https://bit.ly/yolov5-paperspace-notebook\"><img src=\"https://assets.paperspace.io/img/gradient-badge.svg\" alt=\"Run on Gradient\"></a>\n",
        "  <a href=\"https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "  <a href=\"https://www.kaggle.com/ultralytics/yolov5\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open In Kaggle\"></a>\n",
        "<br>\n",
        "\n",
        "This <a href=\"https://github.com/ultralytics/yolov5\">YOLOv5</a> ðŸš€ notebook by <a href=\"https://ultralytics.com\">Ultralytics</a> presents simple train, validate and predict examples to help start your AI adventure.<br>We hope that the resources in this notebook will help you get the most out of YOLOv5. Please browse the YOLOv5 <a href=\"https://docs.ultralytics.com/yolov5\">Docs</a> for details, raise an issue on <a href=\"https://github.com/ultralytics/yolov5\">GitHub</a> for support, and join our <a href=\"https://discord.gg/n6cFeSPZdD\">Discord</a> community for questions and discussions!\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Clone GitHub [repository](https://github.com/ultralytics/yolov5), install [dependencies](https://github.com/ultralytics/yolov5/blob/master/requirements.txt) and check PyTorch and GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbvMlHd_QwMG"
      },
      "outputs": [],
      "source": [
        "%cd ..\n",
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt  # install\n",
        "%cd data\n",
        "!wget -O grapes.yaml https://www.dropbox.com/s/2fa5kd8hzccsgx0/grapes.yaml?dl=0\n",
        "%cd ..\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()  # checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2lvcWuBWqO2"
      },
      "outputs": [],
      "source": [
        "%cd ..\n",
        "%cd content\n",
        "!wget -O data.zip https://zenodo.org/record/6757555/files/wGrapeUNIPD-DL%20dataset.zip?download=1\n",
        "!unzip data.zip\n",
        "!rm wGrapeUNIPD-DL\\ dataset/Calibrated_Images/without_Conting/Chardonnay_BBCH75_20_06_20/_DSC8819.jpg\n",
        "!rm wGrapeUNIPD-DL\\ dataset/Calibrated_Images/without_Conting/Chardonnay_BBCH75_20_06_20/_DSC8819.txt\n",
        "!rm wGrapeUNIPD-DL\\ dataset/Calibrated_Images/with_Counting/Multiple_Cultivar_BBCH83_13_08_20/_counting.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jR2f9jZk4pH"
      },
      "outputs": [],
      "source": [
        "%cd ..\n",
        "!rm -r /datasets/grapes/\n",
        "!mkdir /datasets\n",
        "!rm -r /datasets/grapes/labels_eval/\n",
        "!rm -r /datasets/grapes/images_eval/\n",
        "\n",
        "!mkdir /datasets/grapes/\n",
        "!mkdir /datasets/grapes/labels/\n",
        "!mkdir /datasets/grapes/images/\n",
        "!mkdir /datasets/grapes/labels/train\n",
        "!mkdir /datasets/grapes/images/train\n",
        "!mkdir /datasets/grapes/labels/val\n",
        "!mkdir /datasets/grapes/images/val\n",
        "!cp /content/wGrapeUNIPD-DL\\ dataset/Calibrated_Images/*/*/*.txt /datasets/grapes/labels/train/\n",
        "!cp /content/wGrapeUNIPD-DL\\ dataset/Calibrated_Images/*/*/*.jpg /datasets/grapes/images/train/\n",
        "!cp /content/wGrapeUNIPD-DL\\ dataset/Calibrated_Images/*/*/*.JPG /datasets/grapes/images/train/\n",
        "\n",
        "\n",
        "!rm /datasets/grapes/labels/train/_DSC8819.txt\n",
        "!rm /datasets/grapes/images/train/_DSC8819.jpg\n",
        "\n",
        "import os\n",
        "import random\n",
        "lst = sorted(os.listdir(\"/datasets/grapes/labels/train/\"))\n",
        "lst_imgs = sorted(os.listdir(\"/datasets/grapes/images/train/\"))\n",
        "\n",
        "indici= random.sample(range(0, len(lst)-1), int(len(lst)*0.2))\n",
        "print(len(lst), len(lst_imgs))\n",
        "print(indici)\n",
        "for i in indici:\n",
        "  str_lab= \"/datasets/grapes/labels/train/\"+lst[i]\n",
        "  str_img= \"/datasets/grapes/images/train/\"+lst_imgs[i]\n",
        "  !mv $str_lab /datasets/grapes/labels/val/\n",
        "  !mv $str_img /datasets/grapes/images/val/\n",
        "\n",
        "print(len(os.listdir(\"/datasets/grapes/labels/train\")), len(os.listdir(\"/datasets/grapes/labels/val\")))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JnkELT0cIJg"
      },
      "source": [
        "# 1. Detect\n",
        "\n",
        "`detect.py` runs YOLOv5 inference on a variety of sources, downloading models automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases), and saving results to `runs/detect`. Example inference sources are:\n",
        "\n",
        "```shell\n",
        "python detect.py --source 0  # webcam\n",
        "                          img.jpg  # image\n",
        "                          vid.mp4  # video\n",
        "                          screen  # screenshot\n",
        "                          path/  # directory\n",
        "                         'path/*.jpg'  # glob\n",
        "                         'https://youtu.be/Zgi9g1ksQHc'  # YouTube\n",
        "                         'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkAzDWJ7cWTr"
      },
      "source": [
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img align=\"left\" src=\"https://user-images.githubusercontent.com/26833433/127574988-6a558aa1-d268-44b9-bf6b-62d4c605cc72.jpg\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY2VXXXu74w5"
      },
      "source": [
        "# 2. Train\n",
        "\n",
        "<p align=\"\"><a href=\"https://bit.ly/ultralytics_hub\"><img width=\"1000\" src=\"https://github.com/ultralytics/assets/raw/main/im/integrations-loop.png\"/></a></p>\n",
        "Close the active learning loop by sampling images from your inference conditions with the `roboflow` pip package\n",
        "<br><br>\n",
        "\n",
        "Train a YOLOv5s model on the [COCO128](https://www.kaggle.com/ultralytics/coco128) dataset with `--data coco128.yaml`, starting from pretrained `--weights yolov5s.pt`, or from randomly initialized `--weights '' --cfg yolov5s.yaml`.\n",
        "\n",
        "- **Pretrained [Models](https://github.com/ultralytics/yolov5/tree/master/models)** are downloaded\n",
        "automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases)\n",
        "- **[Datasets](https://github.com/ultralytics/yolov5/tree/master/data)** available for autodownload include: [COCO](https://github.com/ultralytics/yolov5/blob/master/data/coco.yaml), [COCO128](https://github.com/ultralytics/yolov5/blob/master/data/coco128.yaml), [VOC](https://github.com/ultralytics/yolov5/blob/master/data/VOC.yaml), [Argoverse](https://github.com/ultralytics/yolov5/blob/master/data/Argoverse.yaml), [VisDrone](https://github.com/ultralytics/yolov5/blob/master/data/VisDrone.yaml), [GlobalWheat](https://github.com/ultralytics/yolov5/blob/master/data/GlobalWheat2020.yaml), [xView](https://github.com/ultralytics/yolov5/blob/master/data/xView.yaml), [Objects365](https://github.com/ultralytics/yolov5/blob/master/data/Objects365.yaml), [SKU-110K](https://github.com/ultralytics/yolov5/blob/master/data/SKU-110K.yaml).\n",
        "- **Training Results** are saved to `runs/train/` with incrementing run directories, i.e. `runs/train/exp2`, `runs/train/exp3` etc.\n",
        "<br>\n",
        "\n",
        "A **Mosaic Dataloader** is used for training which combines 4 images into 1 mosaic.\n",
        "\n",
        "## Label a dataset on Roboflow (optional)\n",
        "\n",
        "[Roboflow](https://roboflow.com/?ref=ultralytics) enables you to easily **organize, label, and prepare** a high quality dataset with your own custom data. Roboflow also makes it easy to establish an active learning pipeline, collaborate with your team on dataset improvement, and integrate directly into your model building workflow with the `roboflow` pip package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NcFxRcFdJ_O"
      },
      "outputs": [],
      "source": [
        "# Train YOLOv5s on COCO128 for 3 epochs\n",
        "%cd ..\n",
        "%cd yolov5\n",
        "!python train.py --img 1600 --batch 8 --epochs 40 --data grapes.yaml --weights yolov5s.pt --cache"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eq1SMWl6Sfn"
      },
      "source": [
        "# 3. Validate\n",
        "Validate a model's accuracy on the [COCO](https://cocodataset.org/#home) dataset's `val` or `test` splits. Models are downloaded automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases). To show results by class use the `--verbose` flag."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X58w8JLpMnjH"
      },
      "outputs": [],
      "source": [
        "%cd yolov5\n",
        "!python val.py --weights runs/train/exp2/weights/best.pt --data grapes.yaml --img 2432 --half"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!python detect.py --weights runs/train/exp2/weights/best.pt --img 2432 --conf 0.25 --source \"/datasets/grapes/images/val/_DSC9349.jpg\"\n",
        "display.Image(filename='/yolov5/runs/detect/exp5/_DSC9349.jpg', width=2432)"
      ],
      "metadata": {
        "id": "jK6AYhOsfLwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15glLzbQx5u0"
      },
      "source": [
        "# 4. Visualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14WFEvwwZqPi"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir runs/train --port 6007"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HY3awBC7jErk"
      },
      "outputs": [],
      "source": [
        "%cd ..\n",
        "!zip -r /content/file.zip /yolov5/runs/train/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEijrePND_2I"
      },
      "source": [
        "# Appendix\n",
        "\n",
        "Additional content below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMusP4OAxFu6"
      },
      "outputs": [],
      "source": [
        "# YOLOv5 PyTorch HUB Inference (DetectionModels only)\n",
        "import torch\n",
        "\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', force_reload=True)  # yolov5n - yolov5x6 or custom\n",
        "im = 'https://ultralytics.com/images/zidane.jpg'  # file, Path, PIL.Image, OpenCV, nparray, list\n",
        "results = model(im)  # inference\n",
        "results.print()  # or .show(), .save(), .crop(), .pandas(), etc."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}